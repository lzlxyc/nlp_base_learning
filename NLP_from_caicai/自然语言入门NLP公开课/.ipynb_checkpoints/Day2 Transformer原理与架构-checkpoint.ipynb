{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43f845b-1999-4691-bb16-9dea1489a717",
   "metadata": {},
   "source": [
    "# **深度学习公开课 - NLP与GPT&GLM大模型技术**\n",
    "> 节选自《2023深度学习臻选夏季班》正课<br>\n",
    "> 作者：@菜菜TsaiTsai<br>\n",
    "> 版本号：2023/6/16<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb938a86-08f7-4c1c-ae41-f86277167fa8",
   "metadata": {},
   "source": [
    "## **<center><font color =\"k\">公开课Day2 Transformer原理与架构<br><br>极致易学 | 高效入门 | 前景讨论<center>**<br>**<center><font color =\"red\">8点05分正式开始～<br><br>扫码回复\"DL999\"领取今日直播竞赛数据/课件>>><br><br>扫码回复\"618\"抢直播间专属优惠券>>></font></center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0044c4a-5908-4c8a-b9e2-baa2b233be62",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "**Day1 循环神经网络与NLP发展前景**<br><br>\n",
    "1.欢迎来到NLP的世界！<br>\n",
    "2.后GPT时代NLP领域的机遇与挑战<br>\n",
    "3.自然语言领域中的数据<br>\n",
    "4.循环神经网络的网络结构与数据流<br>\n",
    "5.效率问题与RNN的权值共享<br>\n",
    "6.循环神经网络的输入数据结构\n",
    "\n",
    "**Day2 Trasformer原理与架构详解**<br><br>\n",
    "1.Transformer的起点：RNN系列算法的缺陷<br>\n",
    "2.Transformer架构与组成元素<br>\n",
    "3.Embedding层技术概述<br>\n",
    "4.Attention层与QKV矩阵<br>\n",
    "5.残差链接Residual Connection<br>\n",
    "6.NLP中的强制教学策略Teacher Forcing<br>\n",
    "7.Decoder结构与掩码Attention层<br>\n",
    "8.Transformer中的训练与预测数据流\n",
    "\n",
    "**Day3 大语言模型GPT&GLM微调实战**<br>\n",
    "（明日公开）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963bf0a-a196-4bd5-9c29-012987902e17",
   "metadata": {},
   "source": [
    "- 节选自《2023深度学习臻选夏季班》正式课程\n",
    "\n",
    "|2023深度学习甄选夏季班|2023机器学习甄选夏季班|GPT大模型与微调实战课|\n",
    "|:-:|:-:|:-:|\n",
    "|![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.png)|![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%A4%8F%E5%AD%A3%E7%8F%AD.png)|![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%BE%E7%A8%8B.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f665e99-189a-4a9d-8784-3716a48ca29c",
   "metadata": {},
   "source": [
    "## **<center><font color =\"red\">扫码回复\"DL999\"领取今日直播竞赛数据/课件>>><br><br>扫码回复\"618\"抢直播间专属优惠券>>></font></center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566226fb-9977-4dd5-9c1f-0cdf714a16d8",
   "metadata": {},
   "source": [
    "## 1 Transformer起点：RNN系列算法存在的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facdcab-c2eb-4486-bc68-d50b6bdcb232",
   "metadata": {},
   "source": [
    "在Day1的公开课中我们认识了样本与样本之间存在相关性和特定顺序的各种“序列数据”，并且详细解读了专门用来处理序列数据的循环神经网络算法，Transformer算法在RNN算法的基础上做出了重大理念改变，因此开始讲解RNN之前，我们先回顾一下NLP领域的各种基本常识与基本信息。\n",
    "\n",
    "首先，序列数据是一旦打乱样本顺序、或产生样本缺失后就会改变本身含义的数据，其中又以文本和时序数据最为典型。\n",
    "\n",
    "**文本数据（Text Data）**：文本数据中的样本的“特定顺序”是语义的顺序，也就是词与词、句子与句子、段落与段落之间的顺序。在语义环境中，词语顺序的变化或词语的缺失可能会彻底改变语义，例如——\n",
    "> **改变顺序**：事半功倍和事倍功半；曾国藩战太平天国时非常著名的典故：他将“屡战屡败”修改为“屡败屡战”，前者给人绝望，后者给人希望。<br><br>\n",
    "> **样本缺失**（对文本来说特指上下文缺失）：小猫睡在毛毯上，因为它很____。当我们在横线上填上不同的词时，句子的含义会发生变化。\n",
    "\n",
    "当文本数据被编码后，结构如下，其中行是一个单词，列是我们编码时自行设置的编码维度，一张表是一个句子。在这种结构中，一个句子上的单词的总量（也就是二维表的行数）被称之为是vocal_size。\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/06_.png)\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/07_.png)\n",
    "\n",
    "**时间序列数据（Time Series Data）**：时间序列数据中的“特定顺序”就是时间顺序，时序数据中的每个样本就是每个时间点，在不同时间点上存在着不同的标签取值，且这些标签取值常常用于描述某个变量随时间变化的趋势，因此样本之间的顺序不能随意改变。\n",
    "\n",
    "当时序数据被编码后，结构如下，其中行是一个时间点，列是当前时间点上的一个特征，一张表表示了一个对象在不同时间点下的状态。在这种结构中，时间点的总量（也就是二维表的行数）被称之为是时间步，它所在的维度与文本数据中的vocal_size时一样的。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/03_.png)\n",
    "\n",
    "在使用算法学习和处理序列数据时，不仅要保证算法能够理解样本之间的相关性，还必须保证算法能够理解样本之间的先后顺序。对时间序列数据来说，算法必须能够理解“时间是从前往后的、时间只能用过去预测未来”等规则，对文字数据来说，算法必须能够理解“上下文含义”、“只能用句子前面的词预测后面的词”等基本规则。RNN系列算法（如GRU、LSTM、双向RNN等）正是为了处理序列数据才被设计出来的算法群，因此RNN算法有如下特点：\n",
    "\n",
    "1. 普通深度神经网络会在一次正向传播中处理完一张二维表，但是RNN系列算法则会沿着每张二维表的行方向进行**逐行处理**，对文本数据来说，RNN每次向前传播只处理一个单词，一次训练总共会进行vocal_size次向前传播。**这样虽然费时费力，但是可以让RNN算法捕捉到样本的顺序关系**，先进行向传播的单词自然就是在前的样本。\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/10.png)\n",
    "\n",
    "2. 基于这样的数据流设置，循环神经网络构建了自己的**灵魂结构：循环数据流**。在多次进行正向传播的过程中，循环神经网络会将每个单词的信息向下传递给下一个单词，从而让网络在处理下一个单词时还能够“记得”上一个单词的信息。\n",
    "\n",
    "如下图所示，在$T_{t-1}$时间步上时，循环网络处理了一个单词，此时隐藏层上输出的中间变量$H_{t-1}$会走向两条数据流，一条数据流是继续向输出层的方向正向传播，另一条则流向了下一个时间步的隐藏层。在$T_{t}$时间步时，隐藏层会结合当前正向传播的输入层传入的$X_t$和上个时间不的隐藏层传来的中间变量$H_{t-1}$共同计算当前隐藏层的输出$H_{t}$。如此，$H_{t}$当中就包含了上一个单词的信息。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/15.png)\n",
    "\n",
    "这个流程是在时间步维度（同时也是vocal_size维度）进行循环，因此该网络被称之为时循环神经网络。通过这种方式，循环网络进行完所有向前传播后，就会包含所单词的信息，这样也能够让算法理解样本与样本之间的相关性（也就是上下文之间的联系）了。\n",
    "\n",
    "在RNN提出这样的方式后，LSTM、双向RNN的手段也都是基于类似的概念对算法进行了改进，在很长一段时间内，RNN都代表了NLP领域最为核心的关键技术和关键理念，这种理念实践简单并且有效。然而，RNN算法也是存在很大的问题的，这限制了它在某些场景下的性能和应用：\n",
    "\n",
    "1. **难以并行化、运算速度太缓慢**：由于RNN的顺序计算特性，每个时间步的计算依赖于前一个时间步的输出。这使得RNN难以在并行计算中充分发挥计算资源的优势，限制了其在大规模数据上的训练效率和速度。\n",
    "\n",
    "2. **长期依赖问题**：RNN在处理长序列时，由于梯度消失或梯度爆炸的问题，很难捕捉到序列中较远位置的依赖关系。这意味着RNN对于较长的上下文信息的建模能力受到限制，影响了在某些任务中的性能。\n",
    "\n",
    "3. **信息遗忘**：由于RNN的循环结构，网络在处理长序列时容易遗忘较早的信息。这是因为RNN中的隐藏状态在每个时间步都会被更新，早期的信息可能会被新的信息逐渐替代，导致网络难以记住长期的上下文信息。\n",
    "\n",
    "4. **参数量大**：RNN中的基本结构与DNN一致，因此也继承了DNN的核心缺陷参数量大。除了全部使用全链接外，RNN中的参数量与序列长度成正比，因为每个时间步都需要更新一组参数。这导致当序列长度较长时，模型需要较大的内存和计算资源来存储和处理大量的参数，增加了训练和推理的成本。\n",
    "\n",
    "5. **输入顺序依赖**：RNN的计算过程是顺序的，输入的顺序对于模型的输出具有重要影响。这意味着如果输入序列的顺序发生变化，模型的输出也会发生变化。这对于某些任务（如机器翻译）来说是一个问题，因为它们需要对输入序列的排列进行不变的建模。\n",
    "\n",
    "这些缺陷使得RNN在某些情况下面临挑战，尤其是处理长序列、并行计算和捕捉长期依赖关系时，也因此，NLP领域在RNN被提出5年之后开始沉寂。2015年前后，业界有着“NLP领域全面停滞”的消极声音，和当时不断提出新架构、十分光鲜亮丽的GAN、CNN领域比起来，NLP领域曾经一度显得有些萧瑟，但技术的沉淀终究会结出好的果实——\n",
    "\n",
    "2015年Google提出了Transformer架构，这是一种全新的序列建模方式，首次将自注意力机制引、残差链接等概念引入到了NLP领域中，并通过独特的架构设计，使得模型能够同时关注到序列中的不同位置，并且能够并行计算，大幅提升了NLP领域的效率和预测精度。今天，Transformer模型是大语言模型BERT和GPT系列的根基，它可以被用于图像数据、视频数据，可以被用于预测任务、生成任务，可以说是风头无两。\n",
    "\n",
    "那强大的Transformer模型究竟从哪些角度改进了RNN呢？\n",
    "\n",
    "1. **放弃“逐行学习”的方式**，一次性学习一整张表单以提升效率，使用位置编码来让模型学习上下文的顺序。\n",
    "\n",
    "2. **放弃“循环链接”**，不再让靠后的单词携带更多的信息，而使用自注意力机制来让模型学习上下文中的联系。\n",
    "\n",
    "3. **放弃一次性生成一个句子，转而变成一次性生成一个单词**，transformer的终极目标是不断预测”最为合适的下一个词”，它会计算不同合适的词的概率、并输出有效概率最大的那个词作为句子中的下一个单词。\n",
    "\n",
    "4. **加深了对语义的理解**，创造了QKV三种语义信息模式，重新定义了“上下文联系”的数学定义和概念\n",
    "\n",
    "除此之外，还增加了许多训练和处理的技巧，让整个NLP领域的训练思路脱胎换骨。今天我们就来一起看看Transformer架构的各种细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b94444-f6d2-41e2-9577-1dc1f09d02c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Transformer架构与组成元素"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cca6ef-3bf8-40ba-8b72-b87acc6672ce",
   "metadata": {},
   "source": [
    "让我们一起来看看Transformer算法都由哪些元素组成，以下是来自论文《All you need is Attention》的架构图："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83d45d-f4e4-4ffe-916e-7612d395a5a8",
   "metadata": {},
   "source": [
    "![](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ccde11-5b80-4378-bc49-173f0838efcf",
   "metadata": {},
   "source": [
    "Transformer的总体架构主要由两大部分构成：编码器（Encoder）和解码器（Decoder）。在Transformer中，编码是解构自然语言、将自然语言转化为计算机能够理解的信息，并让计算机深度学习数据、理解数据的结构，而解码器是让将算法深度处理过的数据还原回“自然语言”的过程，因此在transformer中，编码器负责接收输入数据，而解码器负责输出最终的标签。\n",
    "\n",
    "编码器（Encoder）结构包括两个子层：一个是自注意力（Self-Attention）层，另一个是前馈（Feed Forward）神经网络。输入会先经过自注意力层，这层的作用是帮助模型关注输入序列中不同位置的信息。然后，经过前馈神经网络层，这是一个简单的全连接神经网络。两个子层都有一个残差连接（Residual Connection）和层标准化（Layer Normalization）。\n",
    "\n",
    "解码器（Decoder）也是由多层的解码器层组成。每个解码器层有三个子层：第一个也是自注意力层（只不过是携带掩码的自注意力层），第二个是注意力层（Attention），第三个是前馈神经网络。自注意力层和前馈神经网络的结构与编码器中的相同。注意力层是用来关注编码器输出的。同样的，每个子层都有一个残差连接和层标准化。\n",
    "\n",
    "现在就让我们从解码器部分开始逐一解读transformer结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6800a5-f692-4c1e-a342-9da9f7e51be3",
   "metadata": {},
   "source": [
    "### 2.1 词嵌入式技术简述（word embedding）\n",
    "\n",
    "你可能注意到了，在编码器和解码器之前还有一个embedding层，这是transformer算法独特的embedding层。Word Embedding，即词嵌入，是自然语言处理（NLP）中的一种关键技术。词嵌入的基本思想是将词汇表中的每一个单词映射到一个多维空间中的向量，这样，每个单词就可以用这个向量来表示，如下图所示：\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/07_.png)\n",
    "\n",
    "**在最初的时候，词嵌入只是一种简单的编码技术**，例如我们将[香蕉、苹果、红富士]编码成[0,1,2]，只是为了让算法能够处理文本类数据，但今天词嵌入技术已经不再那么简单，**当代词嵌入的本质是“基于语义进行编码”（Semantic Embedding），其核心价值在于其成功地编码了词语之间的相似性和语义关系，这是说，在一个规定好的向量空间中，语义相近的词语会被映射到空间中相近的位置，反之亦然**。在当代词嵌入技术中，我们同样编码[香蕉、苹果、红富士]时，我们回得到[0,1,1.1]的结果，而不再是[0,1,2]。\n",
    "\n",
    "如果语义相似的词语可以被编码成相似的向量，这样，我们可以通过计算两个向量的余弦相似性来衡量两个词语的语义相似度。另外，词嵌入还可以捕捉更为复杂的语言现象，比如类比关系。一个经典的例子是，“King - Man + Woman ≈ Queen”，即通过词向量运算，我们可以找到复杂语义关系的词语。\n",
    "\n",
    "词嵌入的训练通常依赖于神经网络模型。其中，最有名的两种模型就是Word2Vec和GloVe。Word2Vec模型有两种变体：连续词袋模型（CBOW）和Skip-gram模型。CBOW预测目标词汇周围的上下文，而Skip-gram则相反，它使用一个词来预测它周围的上下文。GloVe模型则利用全局词频统计信息，试图将全局统计信息和局部上下文信息相结合。\n",
    "\n",
    "词嵌入在NLP任务中发挥着重要作用。无论是文本分类，情感分析，还是更为复杂的任务，如机器翻译和问答系统，词嵌入都是这些系统的重要组成部分，因为它能有效地将离散的文本数据转化为连续的向量数据，使得计算机能更好地理解和处理语言信息。\n",
    "\n",
    "**在正课中我们会详细讲解Word Embedding技术的细节，考虑到公开课时间有限，我们将不会再继续展开**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba8f38a-39b5-4c17-9871-dfba6db8498e",
   "metadata": {},
   "source": [
    "在Transformer中，embedding层位于encoder和decoder之前，主要负责进行语义编码。然而，由于Transformer模型放弃了“逐行对数据进行处理”的方式，而是一次性处理一整张表单，因此它不能直接像循环神经网络RNN那样在训练过程中就捕捉到单词与单词之间的位置信息，因此Transformer引入了位置编码（positional encoding）技术来补充语义词嵌入。位置编码被加到词嵌入上，这样模型就可以同时知道一个词的语义和它在句子中的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fb9fa-1dfc-42bf-b8b1-12b7ce4225fa",
   "metadata": {},
   "source": [
    "![](https://i0.wp.com/kikaben.com/wp-content/uploads/2022/04/image-377.png?resize=800%2C349&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ca5df-2c6f-484f-bc7a-674652da8156",
   "metadata": {},
   "source": [
    "位置编码使用了一种特殊的函数，这个函数会为序列中的每个位置生成一个向量。对于一个特定的位置，这个函数生成的向量在所有维度上的值都是不同的。这保证了每个位置的编码都是唯一的，而且不同位置的编码能够保持一定的相对关系。\n",
    "\n",
    "在Transformer模型中，词嵌入和位置编码被相加，然后输入到模型的第一层。这样，Transformer就可以同时处理词语的语义和它在句子中的位置信息。这也是Transformer模型在处理序列数据，特别是自然语言处理任务中表现出色的一个重要原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f63451-2519-47d8-ac04-6beacd62fba3",
   "metadata": {},
   "source": [
    "Embedding之后，encoder中是什么结构——残差链接与多头注意力机制层，接下来我们就来详细解读一下多头注意力层：\n",
    "\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161ba4f-3174-430b-b23c-218956777f9f",
   "metadata": {},
   "source": [
    "### 2.2 自注意力机制Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c0d12-d1c0-4a8b-ac34-53bcbbb69df3",
   "metadata": {},
   "source": [
    "![](https://data-science-blog.com/wp-content/uploads/2022/01/mha_img_original.png)\n",
    "\n",
    "注意力机制并不是Transformer结构的发明，它是一种在NLP领域中被提出过多次的理念，其核心概念是**赋予序列中不同元素不同的权重来突出序列中的某些部分**，而transformer的成功之处在利用注意力机制建立了样本与样本之间的关系。在一般的注意力机制当中，会有三大步骤：\n",
    "\n",
    "||普通的注意力机制|Transformer中的注意力机制|\n",
    "|:-:|:-:|:-:|\n",
    "|第一步|通过某种方式计算序列上每个元素的权重|用线性层将输入数据X转化为三个结构一致、数据不同的Q、K、V矩阵<br>并利用Q\\*K.T（也就是Q和K矩阵的点积）计算注意力分数|\n",
    "|第二步|对权重进行归一化|归一化，并使用softmax函数将原始注意力分数转变为概率分布<br>这确保了所有的注意力分数都在0和1之间，并且它们的总和为1<br>这意味着我们可以把这些分数看作是对输入元素的相对重要性的度量|\n",
    "|第三步|计算加权求和|每个元素的值V与其对应的注意力分数相乘，得到最终的输出<br>这个输出对输入元素赋予权重后的结果，其中的权重就是注意力分数|\n",
    "\n",
    "在Transformer中，以上三个步骤所构成的公式为：\n",
    "\n",
    "$$AttentionValue(Q, K, V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)·V$$\n",
    "\n",
    "在这个公式中，$d_k$是向量K的维度，softmax就代表softmax函数，而Q、K、V是原始输入的X经过线性层转化来的三个矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add46ef-a217-4447-9b22-83a79cb14aee",
   "metadata": {},
   "source": [
    "- **Q、K、V是什么？Q和K的点积有什么意义？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3796cad-9993-4e84-9a8f-45c16c3b55bc",
   "metadata": {},
   "source": [
    "首先，Q、K、V都是X经过线性层变换后的输出的矩阵，因此实际上Q、K、V是与线性层中相应的权重矩阵相乘而生成的新矩阵。在新矩阵中，Q、K、V中的每一行依然对应着原始X中每一行的信息（如下图，原始矩阵X中有4行、包含4个单词的信息，此时生成的Q、K和V也都会包含4行4个单词的信息）。此时，Q、K、V只是原始矩阵经过不同的信息提取之后得到的矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1076db-f599-4788-a28e-acf617d24bca",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96728f1-7830-413e-a02e-8674ec7d11e1",
   "metadata": {},
   "source": [
    "此时如果我们让Q和K进行点积，则Q的第一行就会与K的第一列相乘，从而得到QK.T矩阵中编号为（1，1）的对象，Q的第一行还会会与K的第二列相乘，从而得到QK.T矩阵中编号为（1，2）的对象。通过这种方法，我们可以求解原始矩阵中的4个单词被编码后的词向量的点积，本质是在计算**原始矩阵中4个单词两两之间的相关性**。当这两个单词之间的相关性较强时，点积的值会更大，当两个单词毫不相关时，点积的值会接近0，因此这一数学过程的本质是在计算单词与自己、单词与其他单词之间的相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09305b99-3598-4d42-87f8-03548f2ac188",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4c136-3958-4982-8edd-f12a6650cbb3",
   "metadata": {},
   "source": [
    "QK.T的值也被称之为时归一化前的注意力分数，在transformer的理论中，如果A单词与B单词点积后的分数越高，两个单词之间的相关性越就高，**这说明算法在学习A单词时应多关注B单词与A单词之间的上下文联系，也就是说算法在学习A单词时应该多放些注意力在B单词上**，这正是注意力机制这一名称的由来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204dcfe-d953-4d84-82ca-84a0ebaf8c68",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98958890-88b7-4eb5-9201-55d70ecf060f",
   "metadata": {},
   "source": [
    "回顾我们之前的例子：\n",
    "\n",
    "小猫睡在毛毯上，因为它很暖。\n",
    "\n",
    "小猫睡在毛毯上，因为它很冷。\n",
    "\n",
    "在这一定义下，**Q、K、V是什么？**\n",
    "\n",
    "- 查询（Query）：查询向量代表了当前的注意力焦点。比如在自然语言处理任务中，当模型在处理一个词时，这个词对应的查询向量就代表了当前的注意力焦点。\n",
    "\n",
    "- 键（Key）：键向量用于和查询向量进行匹配，确定输入中哪些部分与当前的注意力焦点相关。键向量与查询向量的匹配通常通过计算它们的点积来实现。\n",
    "\n",
    "- 值（Value）：值向量包含了输入数据的实际信息，它将被用于生成自注意力机制的输出。每个值向量的重要性由对应的查询向量和键向量的匹配程度确定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26112d33-f702-443b-b467-6dc8e3a62da6",
   "metadata": {},
   "source": [
    "- **你注意到了吗？QK.T的计算方式其实进行了两次相关性计算！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ff101-037e-4fc4-9a53-14b3c677c2be",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eada2c-52f9-4519-be2c-04b06303c474",
   "metadata": {},
   "source": [
    "为什么要这么做？难道单词A与B的相关性，会与单词B与A的相关性不同吗？没错，**在NLP的领域中，以哪个单词为核心来理解语义，会影响词语与词语之间的相关程度**。举例说明：\n",
    "\n",
    "假设我们有这样一个句子：我爱小猫咪。\n",
    "\n",
    "- 如果我们以\"我\"作为查询（Q），那么\"爱\"和\"小猫咪\"在这个上下文中都非常重要。\"爱\"告诉我们\"我\"对\"小猫咪\"的感情是什么，而\"小猫咪\"是\"我\"的感情对象。这个时候，\"爱\"和\"小猫咪\"对\"我\"这个词的上下文重要性就很大。\n",
    "\n",
    "- 但是，如果我们以\"小猫咪\"作为查询（Q），那么\"我\"的重要性就没有那么大了。因为不论是谁爱狗，都不会改变\"小猫咪\"本身。这个时候，\"我\"对\"小猫咪\"这个词的上下文重要性就相对较小。\n",
    "\n",
    "当我们考虑更长的上下文时，这个特点会变得更加显著：\n",
    "\n",
    "- 我爱小猫咪，但妈妈并不喜欢小猫咪。\n",
    "\n",
    "此时对猫咪这个词来说，谁喜欢它就非常重要\n",
    "\n",
    "- 我爱小猫咪，小猫咪非常柔软。\n",
    "\n",
    "此时对猫咪这个词来说，到底是谁喜欢它就无关紧要了，关键是它因为柔软的属性而受人喜爱。\n",
    "\n",
    "这就是为什么我们一定要有Q和K两个矩阵、而不能直接编码之后计算单词两两相关性的原因，这样做让transformer拥有了更大的灵活、也能够解构更深层次的语义。根据下面的图像，在transformr中一个X可以不止有一组Q、K、V，更是可以有多组不同的Q、K、V来从多个角度对语义进行解析，这也是多头注意力为何如此强大的原因了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3aa89-25d8-4e60-af2f-4359f156659b",
   "metadata": {},
   "source": [
    "![](https://data-science-blog.com/wp-content/uploads/2022/01/mha_img_original.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425d625-67ea-4a84-9b8b-0ac49940591d",
   "metadata": {},
   "source": [
    "- **V又是什么**？\n",
    "\n",
    "![](https://data-science-blog.com/wp-content/uploads/2022/01/scaled_dot_product-1536x524.png)\n",
    "\n",
    "在注意力机制中，矩阵V（Value）代表的是每个单词的“值”，或者说“含义”。这是与Query（Q）和Key（K）完全不同的另一种编码。\n",
    "\n",
    "当我们计算了Q和K的点积并进行softmax归一化之后，我们会得到一个注意力权重矩阵。这个注意力权重矩阵代表了在当前上下文下，每个单词对于其他单词的重要性。然后，我们会将这个注意力权重矩阵与V相乘，得到的就是加权的Value，或者说是加权的单词含义。\n",
    "\n",
    "这一步的目的是为了得到每个单词在当前上下文下的表示。简单来说，那些被认为更重要的单词（即注意力权重更大的单词）会在这个表示中占据更大的比重。\n",
    "\n",
    "例如，如果在一个句子中，\"猫\"这个词对于理解整个句子的含义很重要，那么在计算注意力权重的时候，\"猫\"这个词的权重就会比较大。然后，我们会将这个大的权重应用到\"猫\"的Value上，使得\"猫\"的Value在最终的表示中占据更大的比重。\n",
    "\n",
    "总结一下，V在注意力机制中的作用就是给出每个单词的“值”或“含义”，然后根据注意力权重进行加权，得到每个单词在当前上下文下的表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b68b23-053a-441f-a0d2-c83d6601658b",
   "metadata": {},
   "source": [
    "## 2.3 残差链接Residual Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c986ea5-19e2-4ab6-80ae-d381b5b534a1",
   "metadata": {},
   "source": [
    "![](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a13e1-d8b2-495d-9667-ffffa1758578",
   "metadata": {},
   "source": [
    "残差链接又叫做跳跃链接（skip connection）在Transformer模型中起到了很重要的作用，它有助于信息的流动和梯度的传播。具体来说，在Encoder中，跳跃链接允许原始输入与多头注意力层的输出进行直接相加。\n",
    "\n",
    "跳跃链接的存在有以下几个好处：\n",
    "\n",
    "保留原始信息：通过跳跃链接，原始输入能够绕过多头注意力层，直接传递到下一层。这有助于保留输入中的原始信息，防止信息丢失。因为多头注意力层会对输入进行加权处理，将不同位置的信息相互影响和组合，但有时候我们希望保留输入的原始表示。\n",
    "\n",
    "促进信息流动：跳跃链接提供了一种短路机制，使得信息可以更快地在网络中传播。通过直接将原始输入与多头注意力层的输出相加，可以避免梯度在深层网络中消失或爆炸。这样，底层的特征和信息可以更直接地传递到更深层的网络中，有助于模型更好地捕捉输入的细节和上下文信息。\n",
    "\n",
    "缓解训练困难：在深度神经网络中，一些层可能很难训练或梯度消失。通过跳跃链接，可以提供一种捷径，允许梯度更快地回溯到较浅的层，从而缓解训练困难，促进模型的收敛。\n",
    "\n",
    "总的来说，跳跃链接在Transformer中帮助解决了深层网络训练时的梯度消失问题，提高了信息流动的效率，并允许保留原始输入的信息，使模型更好地捕捉输入的特征和上下文。这些跳跃链接在训练过程中起到了重要的作用，使得Transformer模型能够更有效地学习和表示复杂的输入序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa20696-f092-41e2-ade3-1650987ff5a2",
   "metadata": {},
   "source": [
    "## 2.5 NLP中的强制教学策略Teacher Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b00770-481a-4cd2-a62a-98530f8db937",
   "metadata": {},
   "source": [
    "接下来我们将视线转向Decoder结构——\n",
    "\n",
    "1. 你是否注意到，decoder结构的输入和输出都是output？也就是真实标签？\n",
    "\n",
    "2. 为什么decoder结构要将真实标签进行输入？这不是妥妥的数据泄漏吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edce9dd-8a41-462e-b716-fb6f82fc4466",
   "metadata": {},
   "source": [
    "![](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f867f9-9113-4954-aaf9-19cfd10fe031",
   "metadata": {},
   "source": [
    "还记得在开头的时候我们说过，transformer会一个词、一个词地进行预测吗？也就是transformer中上一个词的信息会影响到下一个词的预测，在这个过程中，如果其中一个词被预测错误，那整个句子可能都会面临被预测错误的风险，随着预测出的错误越来越多，算法预测出的结果会越来越离谱。\n",
    "\n",
    "为了解决这个问题，NLP领域引入了\"强制教学策略\"（Teacher Forcing）策略，这是是一种在训练循环神经网络（RNNs）以及一些自回归模型如Transformer等模型时常用的方法。它的基本思想是在训练过程中，模型在每个时间步预测下一个单词时，都使用真实的目标序列的当前时间步的单词作为输入，而不是使用模型在上一个时间步的预测输出作为输入。\n",
    "\n",
    "输入：“I like apples”\n",
    "\n",
    "输出：我喜欢苹果。\n",
    "\n",
    "举个例子，如果我们正在训练一个机器翻译模型，翻译一个句子 \"I like apples\" 到 \"我喜欢苹果\"。在不使用教师强制的情况下，我们会先给模型输入 \"I like apples\"，让它预测出 \"我\"，然后将 \"我\" 作为下一个时间步的输入，再让它预测 \"喜欢\"，以此类推。这种方式的问题在于，一旦模型在某个时间步预测错误，这个错误就会传递到后面的时间步，导致后续的预测都可能出错。例如，如果模型在预测 \"喜欢\" 时出错，预测成了 \"讨厌\"，那么在下一个时间步，模型就需要从 \"我讨厌\" 开始预测，这将很可能导致 \"苹果\" 的预测出错。\n",
    "\n",
    "而如果我们使用了教师强制，就可以避免这种错误的累积。具体来说，无论模型在上一个时间步的预测是什么，我们都会给它输入真实的目标序列的当前时间步的单词，让它预测下一个单词。也就是说，即使模型在预测 \"喜欢\" 时出错，我们在下一个时间步还是会给它输入 \"喜欢\"，让它预测 \"苹果\"，这样就可以避免 \"喜欢\" 的错误影响到 \"苹果\" 的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ece80-dc25-484b-a93a-cc9cbc75a341",
   "metadata": {},
   "source": [
    "## 2.6 带掩码的多头注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88760c9-d6a4-44f8-af7d-d755825d844d",
   "metadata": {},
   "source": [
    "在Transformer中，使用的是一个叫做\"attention mask\"的机制。这个mask实际上是一个和你的注意力矩阵同样大小的矩阵，但它只包含0和1。在计算注意力得分后（即Q和K的点积后进行softmax之前），这个mask会应用于得分矩阵上，把需要屏蔽的位置标记为一个非常大的负数（例如-1e9）。因为这个大的负数是在进行softmax之前加入的，所以在softmax之后，这些被mask的位置基本上会变为0，从而在实际的注意力计算中被忽视掉。\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-5.png)\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/Live/NLP%26LLMs/2-6.png)\n",
    "\n",
    "为什么使用这样的策略呢？这是因为在自注意力机制中，我们希望模型能够在处理某个词的时候，只关注到它之前的词，而忽略之后的词。因为在训练的时候，我们希望模型能够学习到如何根据前文预测后文，如果模型能够看到后文，那么就相当于是“作弊”，这样训练出的模型并不能很好地学习到预测后文的能力。因此我们需要使用mask来防止模型“作弊”。\n",
    "\n",
    "例如，在处理序列 \"I like apples\" 的时候，当我们处理 \"like\" 这个词的时候，我们希望模型只看到 \"I\"，而不看到 \"apples\"。所以我们会在计算 \"like\" 的注意力的时候，对 \"apples\" 这个位置进行mask，使得模型在处理 \"like\" 的时候，无法“看到”\"apples\"。\n",
    "\n",
    "注意，这个mask只在训练的时候使用，在推理的时候，由于我们一次只生成一个词，因此不需要使用mask。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44e783-8160-49d7-a64d-0dca158f59e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ba311-dea5-4f05-a64f-178f618ff32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
